{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Using Deep Learning \n",
    "model having 3 layers. First layer 128 neurons, second layer 64 neurons and third output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\melli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\melli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('intents.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'salam',\n",
       "   'patterns': ['Halo Ara',\n",
       "    'Halo',\n",
       "    'Halo',\n",
       "    'Selamat Pagi',\n",
       "    'Selamat Siang',\n",
       "    'Selamat Malam',\n",
       "    'Selamat Sore',\n",
       "    'Salam'],\n",
       "   'responses': ['Halo! disini Ara untuk ChatBot Pelaporan Pelecehan Seksual. Siapa korban Pelecehan Seksual yang ingin kamu laporkan?',\n",
       "    'Selamat siang disini Ara untuk ChatBot Pelaporan Pelecehan Seksual. Apakah ada laporan pelecehan seksual?',\n",
       "    'Selamat pagi disini Ara untuk ChatBot Pelaporan Pelecehan Seksual. Apakah anda akan melaporkan kasus pelecehan seksual yang korbannya orang lain atau anda sendiri?']},\n",
       "  {'tag': 'laporDiri',\n",
       "   'patterns': ['iya',\n",
       "    'betul',\n",
       "    'gue',\n",
       "    'saya ingin melaporkan kasus pelecehan yang saya alami',\n",
       "    'kasus aku sendiri',\n",
       "    'kasus gue sendiri',\n",
       "    'pelecehan gue sendiri',\n",
       "    'pelecehanku',\n",
       "    'saya mengalami pelecehan sekual',\n",
       "    'ada seseorang berusaha melecehkan saya',\n",
       "    'diri saya'],\n",
       "   'responses': ['Ara ingin membantu, pertama Ara ingin mengetahui identitas kamu korban pelecehan seksual. Apakah kamu mengenal pelaku dan siapakah namanya?',\n",
       "    'Apakah kamu mengetahui identitas pelaku?',\n",
       "    'Apakah kamu mengenal identitas pelaku?',\n",
       "    'Apakah kamu mengetahui siapa namanya']},\n",
       "  {'tag': 'laporOrang',\n",
       "   'patterns': ['orang lain, seorang perempuan penumpang bus',\n",
       "    'orang lain, seorang perempuan yang sedang menyapu',\n",
       "    'orang lain, seorang anak perempuan berinisial',\n",
       "    'wong liyo, seorang anak perempuan',\n",
       "    'orang lain, seorang perempuan',\n",
       "    'orang lain, seorang gadis berinisial',\n",
       "    'orang lain, seorang anak laki-laki difabel inisial S',\n",
       "    'orang lain, korbannya mahasiswi asal Toraja, EL',\n",
       "    'orang lain, mahasiswa jawa tengah',\n",
       "    'orang lain, korbannya bocah berisial AJ',\n",
       "    'orang lain, korbannya seorang pria pengguna jasa layanan ojek online berinisial R',\n",
       "    'orang lain, korbannya merupakan calon penumpang berinisial R',\n",
       "    'orang lain, korbannya penyanyi Brisia Jodie ',\n",
       "    'orang lain, seorang perempuan berinisial N yang menjadi korban pelecehan seksual',\n",
       "    'korbannya seorang murid perempuan',\n",
       "    'korbannya teman gue',\n",
       "    'orang lain ga kenal',\n",
       "    'saudara gue korbannya',\n",
       "    'adik aku korbannya',\n",
       "    'iparku korbannya',\n",
       "    'kakakku korbannya',\n",
       "    'ibuku korbannya',\n",
       "    'ayahku korbannya',\n",
       "    'rekan sekolah',\n",
       "    'korbannya penumpang bus',\n",
       "    'korbannya teman kerja',\n",
       "    'korbannya teman sejawatku'],\n",
       "   'responses': ['Ara ingin membantu, pertama Ara ingin mengetahui identitas kamu korban pelecehan seksual. Apakah kamu mengenal pelaku dan siapakah namanya?',\n",
       "    'Apakah kamu mengenal identitas siapa pelaku tersebut?']},\n",
       "  {'tag': 'hubungan',\n",
       "   'patterns': ['kenal, ayah tirinya',\n",
       "    'tidak kenal identitasnya, pelakunya seorang pengendara sepeda motor datang dari arah belakang langsung memegang pantat korban',\n",
       "    'iya aku mengenal identitasnya, pelaku pelecehan seksualnya tetangganya sendiri',\n",
       "    'tidak kenal identitasnya, tapi pelakunya salah satu tokoh warga masyarakat desa',\n",
       "    'pelakunya memiliki kelainan seks karena menyukai sesama jenis',\n",
       "    'tidak mengenal identitasnya, pelaku seorang pria penumpang bus',\n",
       "    'tentu mengenal, pelakunya tetangganya sendiri',\n",
       "    'tidak mengenal, pelakunya pengemudi ojek online ojol',\n",
       "    'kenal betul, pelakunya ayah tirinya',\n",
       "    'kenal, pelakunya ayahku',\n",
       "    'kenal, pelakunya ayahnya',\n",
       "    'pelakunya kakeknya sendiri',\n",
       "    'pelakunya salah satu Kru TV, Rekan kerja',\n",
       "    'pelakunya pengendara pengemudi sepeda motor tidak dikenal',\n",
       "    'kenal, pelakunya Asisten Pengajar Singapore American School'],\n",
       "   'responses': ['Okai, selanjutnya coba beri tahu Ara, terkait pekerjaan keseharian pelaku dan korban',\n",
       "    'Apa pekerjaan keseharian pelaku?',\n",
       "    'Apa kalian memiliki pekerjaan yang sama? Apakah itu?']},\n",
       "  {'tag': 'pekerjaan',\n",
       "   'patterns': ['pekerjaannya pelaku pengemudi ojek online ojol',\n",
       "    'pelaku bekerja paruh waktu',\n",
       "    'Kades di Lamsel',\n",
       "    'Seorang penjaga sekolah salah satu SD',\n",
       "    'bapak bapak grab',\n",
       "    'pekerjaan pelaku asisten pengajar',\n",
       "    'pekerjaan pelaku',\n",
       "    'gue ga ngerti pekerjaannya dia',\n",
       "    'pekerjaannya seorang makelar pencari penumpang baju merah',\n",
       "    'pekerjaannya ojek online',\n",
       "    'pekerjaannya seorang pengacara',\n",
       "    'pekerjaannya berdagang di pasar'],\n",
       "   'responses': ['Apakah kamu mengetahui usia pelakunya, namun apabila kamu tidak mengetahui kamu bisa memperkirakan saja']},\n",
       "  {'tag': 'usiaPelaku',\n",
       "   'patterns': ['pelaku pemerkosaan seorang ayah',\n",
       "    'pelaku pemerkosaan anak usia 13',\n",
       "    'remaja usia 18-21 tahun',\n",
       "    'pelaku ada yg berusia 10 dan 11 tahun',\n",
       "    'pelaku yang masih 19 tahun',\n",
       "    'pedofil usia 70th',\n",
       "    'seorang remaja berusia 16 tahun',\n",
       "    '',\n",
       "    'umurnya adalah 46 tahun',\n",
       "    'pelaku sekitar usia 20 tahun',\n",
       "    'Kakek Paman dan Pelaku lainnya',\n",
       "    'pelaku si kakek 60 tahun',\n",
       "    'pelaku sekitar usia 20 tahun',\n",
       "    'pelaku pedofil usia 56 tahun',\n",
       "    'usia 50 tahun pelaku pemerkosaan dan pembunuhan',\n",
       "    'usianya 30 tahun',\n",
       "    'seorang bocah usia 7 tahun',\n",
       "    'remaja usia 14 tahun',\n",
       "    'masuk usia',\n",
       "    'usia 6-7 bulan',\n",
       "    'di usia tua',\n",
       "    'umur 40 thn',\n",
       "    'usia pelaku 50 tahun',\n",
       "    'usia 46 thn',\n",
       "    'usianya 30 tahun',\n",
       "    'usia 27 tahun'],\n",
       "   'responses': ['Apa pendidikan yang ditempuh terakhir oleh pelaku?']},\n",
       "  {'tag': 'pendidikanPelaku',\n",
       "   'patterns': ['Pendidikan terakhir pelaku SMA',\n",
       "    'seorang siswi SMP usia 13 tahun',\n",
       "    'Pendidikan pelaku SD',\n",
       "    'Tidak tahu pendidikannya',\n",
       "    'Ga ngerti pendidikan pelaku'],\n",
       "   'responses': ['Berapakah usia korban saat mengalami pelecehan tersebut?',\n",
       "    'Apa pendidikan terakhir yang pernah korban tempuh?']},\n",
       "  {'tag': 'pendidikanKorban',\n",
       "   'patterns': ['Korban berusia 19 tahun',\n",
       "    'Korban berusia 17 tahun',\n",
       "    'usia yang relatif muda yaitu 21 tahun',\n",
       "    'Korban berumur masih SD',\n",
       "    'Korban duduk di bangku SD',\n",
       "    'Korman masih dibangku SMP',\n",
       "    'Korban dibangku kuliah',\n",
       "    'Korban dibangku SMA',\n",
       "    'Korban lulus SMA',\n",
       "    'korban lulusan SMP',\n",
       "    'Korban masih SD'],\n",
       "   'responses': ['Adakah korban lain pada waktu itu? Beri tahu Ara']},\n",
       "  {'tag': 'adaKorbanLain',\n",
       "   'patterns': ['iya, ada dua korban lain',\n",
       "    'aku lihat ada satu korban lainnya',\n",
       "    'gue lihat ada korban lain',\n",
       "    'ada korban lain',\n",
       "    'aku melihat ada korban lainnya'],\n",
       "   'responses': ['Siapakah korban lainnya tersebut. Apakah kamu mengenal korban lainnya?',\n",
       "    'Apakah kamu mengenal korban lainnya?',\n",
       "    'Apakah kamu mengenal korban bersamamu?']},\n",
       "  {'tag': 'korbanLain',\n",
       "   'patterns': ['aku tidak mengenal korban lainnya',\n",
       "    'Muridnya menjadi korban lainnya',\n",
       "    'Korban lain tetangganya',\n",
       "    'penumpang lain juga menjadi korban',\n",
       "    'Nama korban lainnya',\n",
       "    'Mengenal korban lainnya',\n",
       "    'Korban lainnya'],\n",
       "   'responses': ['Baik selanjutnya, kamu dapat menceritakan kronologis/cerita singkat kejadian (apa yang terjadi, kapan, dimana dan bagaimana terjadinya?']},\n",
       "  {'tag': 'tidakadaKorbanLain',\n",
       "   'patterns': ['tidak ada korban lainnya',\n",
       "    'ga ada korban lainnya',\n",
       "    'tidak ada korban lain'],\n",
       "   'responses': ['Baik selanjutnya, kamu dapat menceritakan kronologis/cerita singkat kejadian (apa yang terjadi, kapan, dimana dan bagaimana terjadinya?']},\n",
       "  {'tag': 'kronologi',\n",
       "   'patterns': ['Keluarga awalnya curiga karena perilaku anak ini berubah. Biasanya ceria, tiba-tiba pendiam dan murung. Ditanya kenapa sama keluarga, ceritalah korban, pelaku melakukan aksinya selama kurun waktu',\n",
       "    'Malam kejadian, korban diantar pelaku ke rumah orangtuanya. Pelaku menyebutkan bahwa korban ditiduri oleh pria berinisial JT. Namun, orangtua korban tak mudah percaya. Setelah pelaku pulang, korban ditanya dan ternyata pengakuan korban yang menidurinya adalah pelaku',\n",
       "    'tersangka Ar mengaku melakukan perbuatan itu pertama kali saat melihat korban S sedang jajan di warung tak jauh dari rumahnya. Ia kemudian berpura-pura mengajak korban makan dan membawanya ke rumah untuk dicabuli. Saat itu, korban mendapat kekerasan dari pelaku karena menolak dicabuli',\n",
       "    'kejadian berawal saat adiknya naik bus dari Makassar menuju Toraja. Namun, pada saat di perjalanan bus mengalami mogok. Kemudian penumpang dipindahkan ke bus lainnya dan korban duduk disamping pelaku.Dalam perjalanan suasana berjalan normal, korban sempat berbincang dengan pelaku tentang keluarganya. Pelaku sempat bercerita kalau dia juga punya anak yang seumuran dengan korban. Tak lama setelah itu, korban tidur dan pelaku beraksi dengan cara meraba-raba bagian paha dan alat vital korban. Setelah tersadar korban syok dan tak tahu harus berbuat apa. Dalam kondisi tidur, tiba-tiba ia bangun karena merasa di aba-raba sama pelaku yang duduk di sampingnya. Adik saya langsung menghindar. Dia mau minta tolong tapi katanya tidak bisa, mungkin karena syok,d ucap Fidelis. Saat bus tiba di persinggahan, korban menyampaikan ke sopir tentang kejadian yang dialaminya, sehingga korban dipindahkan duduk kursi samping sopir. Setelah tiba di Toraja, korban bersama keluarganya langsung melapor ke Polres Toraja Utara. Namun laporan korban ditolak oleh Polisi.',\n",
       "    'Mulanya korban keluar rumah sejak Kamis pagi. Namun, setelah pergi lama dan belum kembali, ibu korban pun langsung mencari. Setelah mencari ke tetangga, ibu korban melihat sandal anaknya ada di depan rumah pelaku. Lalu ibunya korban langsung mengetuk-mengetuk rumah pelaku. Namun, pelaku tidak membuka pintu rumahnya. Ibu korban kemudian memanggil-manggil korban agar keluar karena terdengar suara jeritan.',\n",
       "    'Saya awalnya iseng nyalain aplikasi di Pasar Minggu habis dari rumah teman. Terus dapat order ke arah Cipete Utara. Saya klik dan diterima orderan-nya. Calon penumpang itu mengakui lewat percakapan di aplikasi bahwa orderannya bodong. Calon penumpang berinisial R itu bukan memesan layanan ojek online untuk diantar ke suatu tempat. R justru mengajak J untuk berhubungan badan. Lantas, J pun menanggapi pelecehan itu dengan mengajak R ke kantor polisi. Lalu saya balas chat-nya, ayo ke polsek terdekat saja. Selamat Anda terlacak dan masuk Daftar Pencarian Orang. Eh enggak dibalas.',\n",
       "    \"Saat ia sedang menunggu giliran untuk bernyanyi di atas panggung. Jodie hendak membawakan lagu duetnya bersama Arsy, 'Rindu Dalam Hati'. Jadi Arsy di panggung duluan, kan nyanyi part pertama Rindu Dalam Hati tuh, terus kan aku lagi nunggu di belakang. Saat Jodie menunggu giliran bernyanyi, seorang floor director (FD) berbicara padanya. Mulanya hanya basa-basi tak menyangka bahwa sosok di balik layar adalah dirinya. Namun kru TV itu lanjut menyinggung soal berat badan Jodie hingga mengarah pada pelecehan seksual verbal.\",\n",
       "    'Saat itu korban lagi nyapu, itu kan di gang, tiba-tiba pelaku masuk ke gang itu, terus melakukan hal itu (memegang pantat korban) lalu pergi',\n",
       "    'MN diperkosa oleh JP saat istrinya pergi ke pasar untuk berjualan. Saat kejadian, MN dipaksa melayani hawa nafsunya dengan iming-iming akan dibelikan kuota internet. Saat korban menolak, pelaku masih tetap memaksa. Dari keterangan korban, dia sudah berulang kali diperkosa ayah tirinya. Dia tega memperkosa anak tirinya karena sudah lama tidak berhubungan badan dengan istrinya. Setiap saya minta jatah tidak dikasih dan selalu marah-marah. Jadi saya melakukan seperti ini'],\n",
       "   'responses': ['Ara masih belum mengetahui letak kejadiannya, dimana alamat tempat tinggal atau tempat kejadian? Dapat berupa kecamatan dan kabupatennya']},\n",
       "  {'tag': 'bye',\n",
       "   'patterns': ['Terima kasih',\n",
       "    'Terimakasih Ara',\n",
       "    'Thenkyou',\n",
       "    'Thenks',\n",
       "    'Dadah',\n",
       "    'Selamat Tinggal',\n",
       "    'Dah',\n",
       "    'Daah',\n",
       "    'Semoga harimu menyenangkan',\n",
       "    'Ok makasih',\n",
       "    'Ok bye'],\n",
       "   'responses': [\"Terimakasih sudah melaporkan tindakan pelecehan seksual yang terjadi. Let's being this world better, no more silence and stop the violence\",\n",
       "    'Kalau ada masalah dan enggan menceritakan ke orang lain, hubungi Ara lagi ya. World be better if we no more silence and stop the violence',\n",
       "    'Semangat, semoga harimu kedepannya lebih baik! I believe you can be best version peson']}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "\n",
    "        # take each word and tokenize it\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        # adding documents\n",
    "        documents.append((w, intent['tag']))\n",
    "\n",
    "        # adding classes to our class list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "#print (len(documents), \"documents\")\n",
    "#print (len(classes), \"classes\", classes)\n",
    "#print (len(words), \"unique lemmatized words\", words)\n",
    "\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melli\\AppData\\Local\\Temp\\ipykernel_15052\\754323686.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "# initializing training data\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "#shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "#create train and test lists, X = patterns, Y = intens\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay = 1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - 3s 4ms/step - loss: 6.7735 - accuracy: 0.1200\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.4466 - accuracy: 0.1067\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 3.6908 - accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 3.2014 - accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 3.1121 - accuracy: 0.0933\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 3.0328 - accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 3.0322 - accuracy: 0.0933\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 3.0358 - accuracy: 0.0800\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 3.0289 - accuracy: 0.1067\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.9187 - accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.9924 - accuracy: 0.1067\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.8779 - accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.8568 - accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.8361 - accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.8136 - accuracy: 0.0867\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.8164 - accuracy: 0.0933\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.8325 - accuracy: 0.0933\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.7966 - accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.7688 - accuracy: 0.0933\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.7357 - accuracy: 0.1067\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6848 - accuracy: 0.1067\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.7067 - accuracy: 0.1000\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.7141 - accuracy: 0.1200\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6506 - accuracy: 0.1267\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6858 - accuracy: 0.0867\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6044 - accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6837 - accuracy: 0.1000\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.6988 - accuracy: 0.0867\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.6104 - accuracy: 0.1133\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.6559 - accuracy: 0.1000\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.6064 - accuracy: 0.1133\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5649 - accuracy: 0.1200\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5981 - accuracy: 0.1333\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5907 - accuracy: 0.1067\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.5351 - accuracy: 0.1067\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5517 - accuracy: 0.1267\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5572 - accuracy: 0.1067\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5529 - accuracy: 0.1333\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5459 - accuracy: 0.1000\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5346 - accuracy: 0.1333\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4986 - accuracy: 0.1467\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5227 - accuracy: 0.1133\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.5327 - accuracy: 0.0867\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.5237 - accuracy: 0.1267\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4965 - accuracy: 0.1267\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.4872 - accuracy: 0.1000\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.5495 - accuracy: 0.1533\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.4550 - accuracy: 0.1600\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.4328 - accuracy: 0.1667\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3570 - accuracy: 0.2267\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3959 - accuracy: 0.1933\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.5474 - accuracy: 0.2000\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2978 - accuracy: 0.2200\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3216 - accuracy: 0.2400\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.3391 - accuracy: 0.2200\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.3259 - accuracy: 0.2400\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.3359 - accuracy: 0.2667\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.2953 - accuracy: 0.2467\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3048 - accuracy: 0.2067\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.2690 - accuracy: 0.2867\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.2902 - accuracy: 0.2000\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.2884 - accuracy: 0.2667\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.2819 - accuracy: 0.2467\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.2837 - accuracy: 0.2333\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.2508 - accuracy: 0.2667\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3082 - accuracy: 0.2400\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3067 - accuracy: 0.2667\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2577 - accuracy: 0.2733\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2262 - accuracy: 0.2867\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4485 - accuracy: 0.2200\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2254 - accuracy: 0.2267\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2857 - accuracy: 0.2333\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3593 - accuracy: 0.2200\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3284 - accuracy: 0.2400\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3085 - accuracy: 0.2467\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3168 - accuracy: 0.1933\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3810 - accuracy: 0.2200\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3502 - accuracy: 0.2267\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2999 - accuracy: 0.2333\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2227 - accuracy: 0.3067\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2910 - accuracy: 0.2600\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2990 - accuracy: 0.2333\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2392 - accuracy: 0.2333\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.4159 - accuracy: 0.1733\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.3437 - accuracy: 0.1267\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.4436 - accuracy: 0.1800\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.3191 - accuracy: 0.1733\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.4207 - accuracy: 0.1867\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.3959 - accuracy: 0.1733\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.4585 - accuracy: 0.1267\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3128 - accuracy: 0.1600\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3712 - accuracy: 0.1333\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3703 - accuracy: 0.1667\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3816 - accuracy: 0.1667\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3876 - accuracy: 0.1800\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.4262 - accuracy: 0.1867\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3259 - accuracy: 0.1933\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.4249 - accuracy: 0.1667\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4072 - accuracy: 0.1200\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.3871 - accuracy: 0.1200\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3710 - accuracy: 0.1267\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3767 - accuracy: 0.1333\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3486 - accuracy: 0.1667\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3314 - accuracy: 0.1667\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2867 - accuracy: 0.1933\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3167 - accuracy: 0.1667\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4074 - accuracy: 0.1533\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3464 - accuracy: 0.1533\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.3116 - accuracy: 0.1667\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3011 - accuracy: 0.1933\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3273 - accuracy: 0.2067\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2879 - accuracy: 0.2200\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2548 - accuracy: 0.2000\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2845 - accuracy: 0.2067\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.2518 - accuracy: 0.2133\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.2163 - accuracy: 0.2467\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.2191 - accuracy: 0.2467\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.2205 - accuracy: 0.2867\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 2.2509 - accuracy: 0.2400\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.1894 - accuracy: 0.2533\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2101 - accuracy: 0.2000\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1894 - accuracy: 0.2867\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1515 - accuracy: 0.3467\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.1958 - accuracy: 0.2400\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.2896 - accuracy: 0.3000\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.1598 - accuracy: 0.2667\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.1251 - accuracy: 0.3200\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1497 - accuracy: 0.2800\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1733 - accuracy: 0.2800\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1626 - accuracy: 0.2867\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.2552 - accuracy: 0.3067\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.1163 - accuracy: 0.3533\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1330 - accuracy: 0.2867\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.1592 - accuracy: 0.3133\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0866 - accuracy: 0.2933\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.1119 - accuracy: 0.3000\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1202 - accuracy: 0.2867\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0978 - accuracy: 0.3467\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0864 - accuracy: 0.3200\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0667 - accuracy: 0.3533\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.1582 - accuracy: 0.3133\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.0639 - accuracy: 0.3400\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.0725 - accuracy: 0.3400\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0604 - accuracy: 0.3600\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0275 - accuracy: 0.3200\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.0466 - accuracy: 0.3200\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9982 - accuracy: 0.3400\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0392 - accuracy: 0.3533\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9679 - accuracy: 0.3733\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.9894 - accuracy: 0.3533\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.0165 - accuracy: 0.3667\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.0924 - accuracy: 0.3133\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 2.5502 - accuracy: 0.1400\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.6222 - accuracy: 0.1333\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 2.8149 - accuracy: 0.1267\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.4816 - accuracy: 0.1267\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.6630 - accuracy: 0.1333\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.7562 - accuracy: 0.1067\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.7501 - accuracy: 0.0867\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.5635 - accuracy: 0.1133\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.5351 - accuracy: 0.1333\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.6526 - accuracy: 0.1333\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.5831 - accuracy: 0.1267\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4986 - accuracy: 0.1333\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.5457 - accuracy: 0.1333\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4503 - accuracy: 0.1400\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4576 - accuracy: 0.1400\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.4383 - accuracy: 0.1400\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 2.4429 - accuracy: 0.1400\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4332 - accuracy: 0.1467\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4649 - accuracy: 0.1200\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4054 - accuracy: 0.1600\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4313 - accuracy: 0.1267\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4482 - accuracy: 0.1200\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3812 - accuracy: 0.1333\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3888 - accuracy: 0.1333\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3564 - accuracy: 0.1733\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4455 - accuracy: 0.1600\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3441 - accuracy: 0.1333\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3405 - accuracy: 0.1667\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3538 - accuracy: 0.1600\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4112 - accuracy: 0.1467\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3568 - accuracy: 0.1533\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3336 - accuracy: 0.1333\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3759 - accuracy: 0.1400\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3487 - accuracy: 0.1467\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3415 - accuracy: 0.1400\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3414 - accuracy: 0.1800\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3966 - accuracy: 0.1467\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2985 - accuracy: 0.1933\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3241 - accuracy: 0.1600\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2999 - accuracy: 0.1733\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3917 - accuracy: 0.1600\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3166 - accuracy: 0.1667\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.3941 - accuracy: 0.1467\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.3749 - accuracy: 0.1733\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2498 - accuracy: 0.2133\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3757 - accuracy: 0.1667\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.2301 - accuracy: 0.1867\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2858 - accuracy: 0.1600\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "#fitting and saving the model\n",
    "hist=model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print('model created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Make the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.load(open('intents.json', 'rb'))\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b51345ca610e7a8404e7d5913c9c9082c26b7cc9f82c0fb2e4006519af425d45"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
