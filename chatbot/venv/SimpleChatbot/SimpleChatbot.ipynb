{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, let me explained this chatbot. \n",
    "\n",
    "Why i'm rename Simple Chatbot? because this ChatBot just only using Clasification Concept. We have list of input text conversation and output conversation. This chatbot using data history in dataset, so if this Chatbot looking sentences not in training, it cann't detection. I'm not sure this chatbot can be responses using new data from user, but if we want use like that, we can using Generate Chatbot. This my argument has I know, but if you have more knowladge, let's discussion soon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('src/humanText.json') as data_file:\n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textInput</th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halo</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apa Kabar</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selamat Pagi</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      textInput intents\n",
       "0           Hai   salam\n",
       "1            Hi   salam\n",
       "2          Halo   salam\n",
       "3     Apa Kabar   salam\n",
       "4  Selamat Pagi   salam"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textInput = []\n",
    "intents = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        textInput.append(pattern)\n",
    "        intents.append(intent['tag'])\n",
    "\n",
    "df = pd.DataFrame({'textInput': textInput,\n",
    "                    'intents': intents})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salam                 10\n",
       "bye                    8\n",
       "komunitas              7\n",
       "nama                   6\n",
       "pekerjaan              5\n",
       "ngodingpython          5\n",
       "ngodingpython_typo     5\n",
       "youtube                5\n",
       "kemampuan              5\n",
       "Name: intents, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.intents.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleansing\n",
    "import string\n",
    "\n",
    "# convert lowercase\n",
    "df.textInput = df.textInput.apply(lambda x: x.lower())\n",
    "\n",
    "# remove punctuation\n",
    "exclude = set(string.punctuation)\n",
    "df.textInput = df.textInput.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding to labelling tag category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df.intents)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab = []\n",
    "length = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sent = row['textInput']\n",
    "    [all_vocab.append(i) for i in sent.split()]\n",
    "    length.append(len(sent.split()))\n",
    "#len(all_vocab)\n",
    "#max(length)\n",
    "#len(set(all_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization to convert sentences be vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "max_vocab_length = 86\n",
    "max_length = 6\n",
    "\n",
    "text_vectorization = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                       standardize='lower_and_strip_punctuation',\n",
    "                                       split='whitespace',\n",
    "                                       ngrams=None,\n",
    "                                       output_mode='int',\n",
    "                                       output_sequence_length=max_length\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization.adapt(df.textInput)\n",
    "#text_vectorization.get_vocabulary()\n",
    "#text_vectorization('halo ara ingin membantu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding to create arrary from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "embedding = Embedding(input_dim=max_vocab_length,\n",
    "                      output_dim=16,\n",
    "                      embeddings_initializer=\"uniform\",\n",
    "                      input_length=max_length)\n",
    "import numpy as np\n",
    "res_embed = embedding(np.array([[71, 17,  7, 13,  0,  0]]))\n",
    "res_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "inputs = Input(shape=(1,), dtype='string')\n",
    "x = text_vectorization(inputs)\n",
    "x = embedding(x)\n",
    "x = LSTM(12)(x)\n",
    "outputs = Dense(9, activation='softmax')(x)\n",
    "model_lstm = Model(inputs, outputs, name=\"LSTM_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model_lstm.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a86f5aa6b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(df.textInput,\n",
    "               y_train,\n",
    "               epochs=150,\n",
    "               verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 0s/step - loss: 0.1423 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1422586739063263, 1.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.evaluate(df.textInput, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bot_model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bot_model.tf\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001A86B04E080> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save(\"bot_model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "le_filename = open(\"label_encoder.pickle\", \"wb\")\n",
    "pickle.dump(le, le_filename)\n",
    "le_filename.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b51345ca610e7a8404e7d5913c9c9082c26b7cc9f82c0fb2e4006519af425d45"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
